{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following are the instructions to get the results of Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Import data and defined confounders initially"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datatools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initially considered confoudners\n",
    "pre_confounders = [\n",
    "    'saves_pre_period_1',\n",
    "    'follows_pre_period_1',\n",
    "    'playlists_pre_period_1',\n",
    "    'tickets_pre_period_1',\n",
    "    'merch_pre_period_1',\n",
    "    'shares_pre_period_1',\n",
    "    'streams_active_streams_pre_period_1',\n",
    "    'streams_programmed_streams_pre_period_1',\n",
    "    'saves_pre_period_2',\n",
    "    'follows_pre_period_2',\n",
    "    'playlists_pre_period_2',\n",
    "    'tickets_pre_period_2',\n",
    "    'merch_pre_period_2',\n",
    "    'shares_pre_period_2',\n",
    "    'streams_active_streams_pre_period_2',\n",
    "    'streams_programmed_streams_pre_period_2',\n",
    "    'saves_pre_period_3',\n",
    "    'follows_pre_period_3',\n",
    "    'playlists_pre_period_3',\n",
    "    'tickets_pre_period_3',\n",
    "    'merch_pre_period_3',\n",
    "    'shares_pre_period_3',\n",
    "    'cumsaves_pre_period_3',\n",
    "    'cumfollows_pre_period_3',\n",
    "    'cumplaylists_pre_period_3',\n",
    "    'cumtickets_pre_period_3',\n",
    "    'cummerch_pre_period_3',\n",
    "    'cumshares_pre_period_3',\n",
    "    'streams_active_streams_pre_period_3',\n",
    "    'streams_programmed_streams_pre_period_3'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "all_data = load_data('../Data/CausalFandom_main_data.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Run the SMD test to determine the optimal number of clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_list = []\n",
    "post_list = []\n",
    "result_list = []\n",
    "clus_size_list = []\n",
    "smd_before = []\n",
    "\n",
    "pre_outcome = [\n",
    "    'tickets_pre_period_1',\n",
    "    'merch_pre_period_1',\n",
    "    'shares_pre_period_1',\n",
    "    [\n",
    "        'streams_active_streams_pre_period_1',\n",
    "        'streams_programmed_streams_pre_period_1'\n",
    "    ]\n",
    "]\n",
    "\n",
    "post_outcome = [\n",
    "    'tickets_following_four_weeks',\n",
    "    'merch_following_four_weeks',\n",
    "    'shares_following_four_weeks',\n",
    "    [\n",
    "        'streams_active_streams_following_four_weeks',\n",
    "        'streams_programmed_streams_following_four_weeks'\n",
    "    ]\n",
    "]\n",
    "\n",
    "for idx in range(4):\n",
    "    pre_period_name = pre_outcome[idx]\n",
    "    post_period_name = post_outcome[idx]\n",
    "    (control_gap, case_gap) = (-1,2)\n",
    "    sampled_data = all_data.sample(n=5000, replace=False).dropna()\n",
    "\n",
    "    for clus_size in [10,15,20,25,30,35,40,45,50,55,60, 90, 120, 150]:\n",
    "        pre_list.append(pre_period_name)\n",
    "        post_list.append(post_period_name)\n",
    "        clus_size_list.append(clus_size)\n",
    "        confounders = variable_list('art') + variable_list('usr') + pre_confounders\n",
    "        clus_label = kmeans_confoudners(sampled_data, clus_size, confounders)\n",
    "        # Iterate though all sizes\n",
    "        case_control_label = get_case_control_label(pre_period_name,post_period_name,sampled_data,control_gap,case_gap)\n",
    "        smd_before, smd_after, le_before, le_after = smd_calculation_confounders(sampled_data,clus_label,confounders,case_control_label)\n",
    "        diff = np.mean(le_after) - np.mean(le_before)\n",
    "        result_list.append(diff)\n",
    "\n",
    "# Store results for latter visualisation\n",
    "smd = pd.DataFrame(\n",
    "    {\n",
    "    'pre period var':pre_list,\n",
    "    'post period var':post_list,\n",
    "    'clus size' : clus_size_list,\n",
    "    'SMD diff: ': result_list\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The number of clusters decided after running the above is :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Number of cluster of 4 outcomes with and without gaps\n",
    "clus_size_list = [[15,10], [10,10], [15,10], [20,10]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Calculate the statistics ('./plots' directory is needed to store plots)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Produce the statistical results\n",
    "pre_list = []\n",
    "post_list = []\n",
    "thres_list = []\n",
    "smd_list = []\n",
    "result_list = []\n",
    "\n",
    "pre_outcome = [\n",
    "    'tickets_pre_period_1',\n",
    "    'merch_pre_period_1',\n",
    "    'shares_pre_period_1',\n",
    "    [\n",
    "        'streams_active_streams_pre_period_1',\n",
    "        'streams_programmed_streams_pre_period_1'\n",
    "    ]\n",
    "]\n",
    "\n",
    "post_outcome = [\n",
    "    'tickets_following_four_weeks',\n",
    "    'merch_following_four_weeks',\n",
    "    'shares_following_four_weeks',\n",
    "    [\n",
    "        'streams_active_streams_following_four_weeks',\n",
    "        'streams_programmed_streams_following_four_weeks'\n",
    "    ]\n",
    "]\n",
    "\n",
    "for idx in range(4):\n",
    "    pre_period_name = pre_outcome[idx]\n",
    "    post_period_name = post_outcome[idx]\n",
    "    cleaned_data = clean_data(pre_period_name, post_period_name, all_data).dropna()\n",
    "    cur_size_list = clus_size_list[idx]\n",
    "    gap_list = [(0,1),(-1,2)]\n",
    "\n",
    "    for idx1 in range(2) :\n",
    "        (control_gap, case_gap) = gap_list[idx1]\n",
    "        cur_size = cur_size_list[idx1]\n",
    "        # Collect name of the results\n",
    "        thres_list.append((control_gap, case_gap))\n",
    "        pre_list.append(pre_period_name)\n",
    "        post_list.append(post_period_name)\n",
    "        # Get the plot for threshold and ecdf\n",
    "        check_threshold(pre_period_name, post_period_name, cleaned_data, control_gap, case_gap, ifplot= True)\n",
    "        # Produce SMD result\n",
    "        case_control_label = get_case_control_label(pre_period_name, post_period_name, cleaned_data, control_gap, case_gap)\n",
    "        confounders = variable_list('art') + variable_list('usr') + pre_confounders\n",
    "        clus_label = kmeans_confoudners(cleaned_data, cur_size, confounders)\n",
    "        smd_before,smd_after,le_before,le_after = smd_calculation_confounders(cleaned_data, clus_label, confounders, case_control_label)\n",
    "        diff = np.mean(le_after) - np.mean(le_before)\n",
    "        smd_list.append(diff)\n",
    "        # Get the smd plot\n",
    "        smd_plot_calmean(le_before, le_after, pre_period_name, post_period_name, pd.DataFrame(), control_gap, case_gap, name_suffix='originaldata')\n",
    "        # Produce the final result\n",
    "        stat_results = cal_stats(cleaned_data, variable_list('treat_act'), clus_label, case_control_label)\n",
    "        result_list.append(stat_results)\n",
    "\n",
    "result = pd.DataFrame(\n",
    "    {\n",
    "    'pre period var':pre_list,\n",
    "    'post period var':post_list,\n",
    "    'SMD diff: ': smd_list,\n",
    "    'threshold':thres_list\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Save the results locally"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the result to file\n",
    "name_list = []\n",
    "\n",
    "preoutcome = [\n",
    "    'tickets_pre1',\n",
    "    'merch_pre1',\n",
    "    'shares_pre1',\n",
    "    'streams_pre1',\n",
    "]\n",
    "postoutcome = [\n",
    "    'f4k',\n",
    "    'merch_following_four_weeks',\n",
    "    'shares_following_four_weeks',\n",
    "    'streams_following_four_weeks'\n",
    "]\n",
    "\n",
    "for idx in range(4):\n",
    "    pre_period_name = preoutcome[idx]\n",
    "    post_period_name = postoutcome[idx]\n",
    "    gap_list = [(0,1),(-1,2)]\n",
    "    for idx1 in range(2) :\n",
    "        (control_gap, case_gap) = gap_list[idx1]\n",
    "        name = pre_period_name + 'f4k_' + str(control_gap) +'_' + str(case_gap)\n",
    "        name_list.append(name)\n",
    "\n",
    "# Save the result to the local directory (./stat_result)\n",
    "with pd.ExcelWriter('./stat_result/originalresult.xlsx') as writer:\n",
    "    for i in range(len(result_list)):\n",
    "        item =  result_list[i]\n",
    "        item.to_excel(writer, sheet_name=name_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
